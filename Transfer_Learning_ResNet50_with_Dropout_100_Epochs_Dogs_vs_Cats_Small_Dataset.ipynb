{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning - ResNet50 with Dropout - 100 Epochs - Dogs vs. Cats - Small Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfavaits/YouTube-Series-on-Machine-Learning/blob/master/Transfer_Learning_ResNet50_with_Dropout_100_Epochs_Dogs_vs_Cats_Small_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCv4aeLxA1Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7vGwSixv_w",
        "colab_type": "code",
        "outputId": "e1293925-7fc3-42a7-9c1a-42990fd81cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwHsoXL-F0g2",
        "colab_type": "code",
        "outputId": "dbe253e6-acdf-4ed5-ca7d-63096dc09598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "conv_base = ResNet50(weights= 'imagenet', include_top=False, input_shape=(150,150,3))\n",
        "conv_base.summary ()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 75, 75, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 75, 75, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 38, 38, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 38, 38, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 38, 38, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 38, 38, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 38, 38, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 38, 38, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 38, 38, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 19, 19, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 19, 19, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 19, 19, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 10, 10, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 10, 10, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 10, 10, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 10, 10, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 10, 10, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 10, 10, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 10, 10, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 5, 5, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 5, 5, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 5, 5, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 5, 5, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9qcaRMhIV7c",
        "colab_type": "text"
      },
      "source": [
        "The final feature map has shape (5, 5, 2048).\n",
        "We extract features from by calling the predict method on the conv_base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY2SBTzqGgPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "batch_size=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvmu7oI-Go7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(directory, sample_count): #extract features from a directory with JPEG files and sample_count is # files in dir\n",
        "    features=np.zeros(shape=(sample_count, 5, 5, 2048)) # empty array\n",
        "    labels=np.zeros(shape=(sample_count)) # empty array\n",
        "    generator=datagen.flow_from_directory(directory, target_size=(150, 150), batch_size=20, class_mode='binary')\n",
        "    \n",
        "    i=0\n",
        "    for inputs_batch, labels_batch in generator: \n",
        "      features_batch=conv_base.predict(inputs_batch) # extract features from conv_base\n",
        "      features[i*batch_size:(i+1)*batch_size]=features_batch # for i=0 we have features[0:20], for i=2 features[20:40]\n",
        "      labels[i*batch_size:(i+1)*batch_size]=labels_batch\n",
        "      i+=1\n",
        "      if i*batch_size>=sample_count:\n",
        "        break #break when every image has been seen once\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOTxZTTYHiK1",
        "colab_type": "code",
        "outputId": "5cda3921-0988-4796-9b62-cea6a559e0ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_features, train_labels = extract_features('/content/drive/My Drive/Colab Notebooks/training_2000', 2000)\n",
        "validation_features, validation_labels = extract_features('/content/drive/My Drive/Colab Notebooks/val_1000', 1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI5IINhnI-ct",
        "colab_type": "text"
      },
      "source": [
        "The extracted features are currently of shape (samples, 5 , 5, 2048) and we need to flatten before pushing them through a densely connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOHY1sQpIQHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features=np.reshape(train_features, (2000, 5*5*2048))\n",
        "validation_features=np.reshape(validation_features, (1000, 5*5*2048))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10mhjDGSPQee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "aec47e04-d875-4f4d-90e7-4fbd77cc89e8"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=5*5*2048))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fS9kmK0PQZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "45120da5-e3f9-4e8c-dcd1-1b343f3159b8"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu-KKjHzXRix",
        "colab_type": "code",
        "outputId": "a36f405a-39c9-4b76-f555-1a3762c51229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=20, validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.7451 - acc: 0.5400 - val_loss: 0.6980 - val_acc: 0.5190\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6894 - acc: 0.5550 - val_loss: 0.6937 - val_acc: 0.5010\n",
            "Epoch 3/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6736 - acc: 0.5820 - val_loss: 0.6600 - val_acc: 0.6030\n",
            "Epoch 4/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6721 - acc: 0.5805 - val_loss: 0.6497 - val_acc: 0.6240\n",
            "Epoch 5/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6605 - acc: 0.5965 - val_loss: 0.6422 - val_acc: 0.6410\n",
            "Epoch 6/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6574 - acc: 0.6000 - val_loss: 0.6496 - val_acc: 0.6140\n",
            "Epoch 7/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6600 - acc: 0.5925 - val_loss: 0.6430 - val_acc: 0.6060\n",
            "Epoch 8/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6482 - acc: 0.6255 - val_loss: 0.6384 - val_acc: 0.6390\n",
            "Epoch 9/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6451 - acc: 0.6135 - val_loss: 0.6291 - val_acc: 0.6490\n",
            "Epoch 10/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6493 - acc: 0.6195 - val_loss: 0.6373 - val_acc: 0.6210\n",
            "Epoch 11/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6281 - acc: 0.6410 - val_loss: 0.6313 - val_acc: 0.6250\n",
            "Epoch 12/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6340 - acc: 0.6380 - val_loss: 0.6191 - val_acc: 0.6520\n",
            "Epoch 13/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6342 - acc: 0.6360 - val_loss: 0.6394 - val_acc: 0.6340\n",
            "Epoch 14/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6281 - acc: 0.6435 - val_loss: 0.6165 - val_acc: 0.6630\n",
            "Epoch 15/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6218 - acc: 0.6460 - val_loss: 0.6310 - val_acc: 0.6510\n",
            "Epoch 16/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6226 - acc: 0.6505 - val_loss: 0.6094 - val_acc: 0.6640\n",
            "Epoch 17/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6174 - acc: 0.6510 - val_loss: 0.6129 - val_acc: 0.6630\n",
            "Epoch 18/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.6127 - acc: 0.6560 - val_loss: 0.6162 - val_acc: 0.6490\n",
            "Epoch 19/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6177 - acc: 0.6650 - val_loss: 0.6066 - val_acc: 0.6660\n",
            "Epoch 20/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6148 - acc: 0.6580 - val_loss: 0.6071 - val_acc: 0.6610\n",
            "Epoch 21/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6079 - acc: 0.6645 - val_loss: 0.6090 - val_acc: 0.6610\n",
            "Epoch 22/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6034 - acc: 0.6720 - val_loss: 0.6030 - val_acc: 0.6630\n",
            "Epoch 23/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6039 - acc: 0.6715 - val_loss: 0.6051 - val_acc: 0.6720\n",
            "Epoch 24/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6015 - acc: 0.6600 - val_loss: 0.6051 - val_acc: 0.6660\n",
            "Epoch 25/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6064 - acc: 0.6770 - val_loss: 0.6006 - val_acc: 0.6660\n",
            "Epoch 26/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5984 - acc: 0.6735 - val_loss: 0.5924 - val_acc: 0.6910\n",
            "Epoch 27/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5997 - acc: 0.6695 - val_loss: 0.6016 - val_acc: 0.6710\n",
            "Epoch 28/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5976 - acc: 0.6650 - val_loss: 0.5937 - val_acc: 0.6790\n",
            "Epoch 29/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5963 - acc: 0.6780 - val_loss: 0.5957 - val_acc: 0.6750\n",
            "Epoch 30/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5857 - acc: 0.6770 - val_loss: 0.6016 - val_acc: 0.6680\n",
            "Epoch 31/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5835 - acc: 0.6940 - val_loss: 0.5873 - val_acc: 0.6880\n",
            "Epoch 32/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5850 - acc: 0.6945 - val_loss: 0.5965 - val_acc: 0.6810\n",
            "Epoch 33/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5894 - acc: 0.6760 - val_loss: 0.5911 - val_acc: 0.6830\n",
            "Epoch 34/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5830 - acc: 0.6825 - val_loss: 0.5905 - val_acc: 0.6850\n",
            "Epoch 35/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5813 - acc: 0.7015 - val_loss: 0.5891 - val_acc: 0.6860\n",
            "Epoch 36/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5870 - acc: 0.6850 - val_loss: 0.5861 - val_acc: 0.6900\n",
            "Epoch 37/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5782 - acc: 0.6915 - val_loss: 0.6334 - val_acc: 0.6390\n",
            "Epoch 38/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5778 - acc: 0.6870 - val_loss: 0.5883 - val_acc: 0.6760\n",
            "Epoch 39/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5760 - acc: 0.6960 - val_loss: 0.6111 - val_acc: 0.6640\n",
            "Epoch 40/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5774 - acc: 0.6950 - val_loss: 0.5831 - val_acc: 0.6900\n",
            "Epoch 41/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5701 - acc: 0.6995 - val_loss: 0.6158 - val_acc: 0.6440\n",
            "Epoch 42/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5817 - acc: 0.6825 - val_loss: 0.5810 - val_acc: 0.6920\n",
            "Epoch 43/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5707 - acc: 0.6925 - val_loss: 0.6291 - val_acc: 0.6460\n",
            "Epoch 44/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5682 - acc: 0.7005 - val_loss: 0.5812 - val_acc: 0.6900\n",
            "Epoch 45/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5672 - acc: 0.7035 - val_loss: 0.5764 - val_acc: 0.6930\n",
            "Epoch 46/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5686 - acc: 0.7020 - val_loss: 0.5769 - val_acc: 0.6980\n",
            "Epoch 47/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5650 - acc: 0.7000 - val_loss: 0.5891 - val_acc: 0.6890\n",
            "Epoch 48/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5597 - acc: 0.7105 - val_loss: 0.5773 - val_acc: 0.6980\n",
            "Epoch 49/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5645 - acc: 0.6965 - val_loss: 0.5776 - val_acc: 0.6950\n",
            "Epoch 50/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5630 - acc: 0.6975 - val_loss: 0.5781 - val_acc: 0.6930\n",
            "Epoch 51/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5578 - acc: 0.7155 - val_loss: 0.5770 - val_acc: 0.7010\n",
            "Epoch 52/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5610 - acc: 0.7005 - val_loss: 0.5744 - val_acc: 0.6990\n",
            "Epoch 53/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5600 - acc: 0.7140 - val_loss: 0.5745 - val_acc: 0.7010\n",
            "Epoch 54/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5505 - acc: 0.7185 - val_loss: 0.6063 - val_acc: 0.6560\n",
            "Epoch 55/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5575 - acc: 0.7035 - val_loss: 0.5910 - val_acc: 0.6840\n",
            "Epoch 56/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5533 - acc: 0.7075 - val_loss: 0.5763 - val_acc: 0.6900\n",
            "Epoch 57/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5501 - acc: 0.7190 - val_loss: 0.6127 - val_acc: 0.6590\n",
            "Epoch 58/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5472 - acc: 0.7205 - val_loss: 0.6442 - val_acc: 0.6300\n",
            "Epoch 59/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5536 - acc: 0.7215 - val_loss: 0.5803 - val_acc: 0.6920\n",
            "Epoch 60/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5445 - acc: 0.7215 - val_loss: 0.5803 - val_acc: 0.6890\n",
            "Epoch 61/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5416 - acc: 0.7165 - val_loss: 0.5778 - val_acc: 0.6920\n",
            "Epoch 62/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5429 - acc: 0.7250 - val_loss: 0.5694 - val_acc: 0.7070\n",
            "Epoch 63/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5462 - acc: 0.7100 - val_loss: 0.5695 - val_acc: 0.7060\n",
            "Epoch 64/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5512 - acc: 0.7130 - val_loss: 0.5723 - val_acc: 0.6990\n",
            "Epoch 65/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5448 - acc: 0.7230 - val_loss: 0.5679 - val_acc: 0.7110\n",
            "Epoch 66/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5450 - acc: 0.7130 - val_loss: 0.5890 - val_acc: 0.6820\n",
            "Epoch 67/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5439 - acc: 0.7170 - val_loss: 0.5919 - val_acc: 0.6660\n",
            "Epoch 68/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5408 - acc: 0.7195 - val_loss: 0.5743 - val_acc: 0.6960\n",
            "Epoch 69/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5398 - acc: 0.7205 - val_loss: 0.5703 - val_acc: 0.7070\n",
            "Epoch 70/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5399 - acc: 0.7215 - val_loss: 0.5710 - val_acc: 0.7100\n",
            "Epoch 71/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5347 - acc: 0.7235 - val_loss: 0.6335 - val_acc: 0.6430\n",
            "Epoch 72/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5401 - acc: 0.7260 - val_loss: 0.5748 - val_acc: 0.6960\n",
            "Epoch 73/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5323 - acc: 0.7240 - val_loss: 0.5885 - val_acc: 0.6700\n",
            "Epoch 74/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5332 - acc: 0.7285 - val_loss: 0.5711 - val_acc: 0.6980\n",
            "Epoch 75/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5403 - acc: 0.7355 - val_loss: 0.5676 - val_acc: 0.7120\n",
            "Epoch 76/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5261 - acc: 0.7325 - val_loss: 0.5829 - val_acc: 0.6900\n",
            "Epoch 77/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5339 - acc: 0.7225 - val_loss: 0.5707 - val_acc: 0.7050\n",
            "Epoch 78/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5272 - acc: 0.7325 - val_loss: 0.5936 - val_acc: 0.6640\n",
            "Epoch 79/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5293 - acc: 0.7335 - val_loss: 0.5674 - val_acc: 0.6980\n",
            "Epoch 80/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5252 - acc: 0.7270 - val_loss: 0.5660 - val_acc: 0.6960\n",
            "Epoch 81/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5292 - acc: 0.7330 - val_loss: 0.5671 - val_acc: 0.7120\n",
            "Epoch 82/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5191 - acc: 0.7445 - val_loss: 0.6013 - val_acc: 0.6830\n",
            "Epoch 83/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5202 - acc: 0.7360 - val_loss: 0.5804 - val_acc: 0.6900\n",
            "Epoch 84/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5251 - acc: 0.7305 - val_loss: 0.5684 - val_acc: 0.7000\n",
            "Epoch 85/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5243 - acc: 0.7315 - val_loss: 0.5782 - val_acc: 0.6920\n",
            "Epoch 86/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5249 - acc: 0.7380 - val_loss: 0.5684 - val_acc: 0.7060\n",
            "Epoch 87/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5244 - acc: 0.7350 - val_loss: 0.5830 - val_acc: 0.6890\n",
            "Epoch 88/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5209 - acc: 0.7465 - val_loss: 0.5933 - val_acc: 0.6760\n",
            "Epoch 89/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5170 - acc: 0.7405 - val_loss: 0.5636 - val_acc: 0.7100\n",
            "Epoch 90/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5135 - acc: 0.7480 - val_loss: 0.5677 - val_acc: 0.7010\n",
            "Epoch 91/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5220 - acc: 0.7360 - val_loss: 0.5656 - val_acc: 0.7030\n",
            "Epoch 92/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5180 - acc: 0.7350 - val_loss: 0.5679 - val_acc: 0.7110\n",
            "Epoch 93/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5257 - acc: 0.7370 - val_loss: 0.6648 - val_acc: 0.6340\n",
            "Epoch 94/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5071 - acc: 0.7475 - val_loss: 0.5690 - val_acc: 0.7050\n",
            "Epoch 95/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5151 - acc: 0.7455 - val_loss: 0.5870 - val_acc: 0.6800\n",
            "Epoch 96/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5065 - acc: 0.7465 - val_loss: 0.5651 - val_acc: 0.6960\n",
            "Epoch 97/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5129 - acc: 0.7475 - val_loss: 0.5688 - val_acc: 0.7060\n",
            "Epoch 98/100\n",
            "2000/2000 [==============================] - 17s 8ms/step - loss: 0.5159 - acc: 0.7410 - val_loss: 0.5869 - val_acc: 0.6800\n",
            "Epoch 99/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5170 - acc: 0.7415 - val_loss: 0.5854 - val_acc: 0.6830\n",
            "Epoch 100/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5117 - acc: 0.7435 - val_loss: 0.5746 - val_acc: 0.7010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxBFfQjwXRVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7MVm5FeXRLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=range(1, len(acc)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sAK6k2LXRDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e8f77909-df85-44b5-b544-2713850994c5"
      },
      "source": [
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}