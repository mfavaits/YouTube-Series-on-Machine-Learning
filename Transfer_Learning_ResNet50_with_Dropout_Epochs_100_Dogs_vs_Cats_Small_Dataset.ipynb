{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning - ResNet50 with Dropout - Epochs 100 - Dogs vs. Cats - Small Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfavaits/YouTube-Series-on-Machine-Learning/blob/master/Transfer_Learning_ResNet50_with_Dropout_Epochs_100_Dogs_vs_Cats_Small_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCv4aeLxA1Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7vGwSixv_w",
        "colab_type": "code",
        "outputId": "3ae29024-80c2-4ec6-f433-bdc6eb8fea04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNjlT8w6RVqk",
        "colab_type": "code",
        "outputId": "b0fb58bc-c788-467c-e910-f11229d01c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "conv_base = ResNet50(weights= 'imagenet', include_top=False, input_shape=(150,150,3))\n",
        "conv_base.summary ()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 75, 75, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 75, 75, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 38, 38, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 38, 38, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 38, 38, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 38, 38, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 38, 38, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 38, 38, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 38, 38, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 38, 38, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 38, 38, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 38, 38, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 38, 38, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 38, 38, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 38, 38, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 38, 38, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 38, 38, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 19, 19, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 19, 19, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 19, 19, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 19, 19, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 19, 19, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 19, 19, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 19, 19, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 19, 19, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 19, 19, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 19, 19, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 19, 19, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 19, 19, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 19, 19, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 19, 19, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 19, 19, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 19, 19, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 10, 10, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 10, 10, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 10, 10, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 10, 10, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 10, 10, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 10, 10, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10, 10, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 10, 10, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 10, 10, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 10, 10, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 10, 10, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 10, 10, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 10, 10, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 10, 10, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 10, 10, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 10, 10, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 10, 10, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 10, 10, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 10, 10, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 10, 10, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 10, 10, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 10, 10, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 10, 10, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 10, 10, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 10, 10, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 5, 5, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 5, 5, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 5, 5, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 5, 5, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 5, 5, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 5, 5, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 5, 5, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 5, 5, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 5, 5, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 5, 5, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 5, 5, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 5, 5, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 5, 5, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 5, 5, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 5, 5, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 5, 5, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 5, 5, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP95CvyySlGR",
        "colab_type": "text"
      },
      "source": [
        "The final feature map has shape (5, 5, 2048).\n",
        "We extract features from by calling the predict method on the conv_base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG9B4zpVRXPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "batch_size=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubyhKtLERXNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(directory, sample_count): #extract features from a directory with JPEG files and sample_count is # files in dir\n",
        "    features=np.zeros(shape=(sample_count, 5, 5, 2048)) # empty array for features\n",
        "    labels=np.zeros(shape=(sample_count)) # empty array for labels\n",
        "    generator=datagen.flow_from_directory(directory, target_size=(150, 150), batch_size=20, class_mode='binary')\n",
        "    \n",
        "    i=0\n",
        "    for inputs_batch, labels_batch in generator: \n",
        "      features_batch=conv_base.predict(inputs_batch) # extract features from conv_base\n",
        "      features[i*batch_size:(i+1)*batch_size]=features_batch # for i=0 we have features[0:20], for i=1 features[20:40]\n",
        "      labels[i*batch_size:(i+1)*batch_size]=labels_batch     # for i=0 we have features[0:20], for i=1 features[20:40]\n",
        "      i+=1\n",
        "      if i*batch_size>=sample_count:\n",
        "        break #break when every image has been seen once\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQE4WV2ARXKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b95ada31-92ea-48b9-f716-35a42b72d5d6"
      },
      "source": [
        "train_features, train_labels = extract_features('/content/drive/My Drive/Colab Notebooks/training_2000', 2000)\n",
        "validation_features, validation_labels = extract_features('/content/drive/My Drive/Colab Notebooks/val_1000', 1000)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX48m6RUXvUq",
        "colab_type": "text"
      },
      "source": [
        "The extracted features are currently of shape (samples, 5 , 5, 2048) and we need to flatten before pushing them through a densely connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ndrhhgiRXG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features=np.reshape(train_features, (2000, 5*5*2048))\n",
        "validation_features=np.reshape(validation_features, (1000, 5*5*2048))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbcxfY3jRXDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "02419d3f-c878-4dab-d8a5-15ac2235fc24"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=5*5*2048))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4qm2acARXBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "961cfc65-2778-40d9-f2ce-60ced7da10d0"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sGIqGE8RW_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fd6ca75-31be-4a62-dbab-cb5677fc4846"
      },
      "source": [
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=20, validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.7558 - acc: 0.5215 - val_loss: 0.6699 - val_acc: 0.6020\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6888 - acc: 0.5715 - val_loss: 0.6732 - val_acc: 0.5610\n",
            "Epoch 3/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6773 - acc: 0.5765 - val_loss: 0.6651 - val_acc: 0.5710\n",
            "Epoch 4/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6680 - acc: 0.5895 - val_loss: 0.6503 - val_acc: 0.6090\n",
            "Epoch 5/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6614 - acc: 0.6015 - val_loss: 0.6695 - val_acc: 0.5720\n",
            "Epoch 6/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6578 - acc: 0.6060 - val_loss: 0.6438 - val_acc: 0.6340\n",
            "Epoch 7/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6582 - acc: 0.6030 - val_loss: 0.6409 - val_acc: 0.6360\n",
            "Epoch 8/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6479 - acc: 0.6165 - val_loss: 0.6513 - val_acc: 0.5950\n",
            "Epoch 9/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6378 - acc: 0.6340 - val_loss: 0.6322 - val_acc: 0.6350\n",
            "Epoch 10/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6424 - acc: 0.6345 - val_loss: 0.6279 - val_acc: 0.6420\n",
            "Epoch 11/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6284 - acc: 0.6390 - val_loss: 0.6243 - val_acc: 0.6520\n",
            "Epoch 12/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6381 - acc: 0.6330 - val_loss: 0.6274 - val_acc: 0.6520\n",
            "Epoch 13/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6333 - acc: 0.6305 - val_loss: 0.6257 - val_acc: 0.6390\n",
            "Epoch 14/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6281 - acc: 0.6505 - val_loss: 0.6207 - val_acc: 0.6500\n",
            "Epoch 15/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6221 - acc: 0.6400 - val_loss: 0.6168 - val_acc: 0.6550\n",
            "Epoch 16/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6199 - acc: 0.6430 - val_loss: 0.6170 - val_acc: 0.6570\n",
            "Epoch 17/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6212 - acc: 0.6545 - val_loss: 0.6578 - val_acc: 0.5890\n",
            "Epoch 18/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6146 - acc: 0.6525 - val_loss: 0.6266 - val_acc: 0.6250\n",
            "Epoch 19/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6182 - acc: 0.6600 - val_loss: 0.6119 - val_acc: 0.6560\n",
            "Epoch 20/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6091 - acc: 0.6665 - val_loss: 0.6093 - val_acc: 0.6620\n",
            "Epoch 21/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6069 - acc: 0.6575 - val_loss: 0.6011 - val_acc: 0.6720\n",
            "Epoch 22/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6025 - acc: 0.6790 - val_loss: 0.5997 - val_acc: 0.6670\n",
            "Epoch 23/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6036 - acc: 0.6755 - val_loss: 0.6137 - val_acc: 0.6610\n",
            "Epoch 24/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6013 - acc: 0.6815 - val_loss: 0.5980 - val_acc: 0.6770\n",
            "Epoch 25/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5988 - acc: 0.6660 - val_loss: 0.5984 - val_acc: 0.6800\n",
            "Epoch 26/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.6029 - acc: 0.6690 - val_loss: 0.6300 - val_acc: 0.6460\n",
            "Epoch 27/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6037 - acc: 0.6685 - val_loss: 0.6024 - val_acc: 0.6640\n",
            "Epoch 28/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5942 - acc: 0.6800 - val_loss: 0.5953 - val_acc: 0.6820\n",
            "Epoch 29/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5951 - acc: 0.6775 - val_loss: 0.6313 - val_acc: 0.6190\n",
            "Epoch 30/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5893 - acc: 0.6825 - val_loss: 0.5899 - val_acc: 0.6830\n",
            "Epoch 31/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5871 - acc: 0.6760 - val_loss: 0.6316 - val_acc: 0.6290\n",
            "Epoch 32/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5851 - acc: 0.6855 - val_loss: 0.5918 - val_acc: 0.6810\n",
            "Epoch 33/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5869 - acc: 0.6955 - val_loss: 0.5941 - val_acc: 0.6700\n",
            "Epoch 34/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5873 - acc: 0.6790 - val_loss: 0.6001 - val_acc: 0.6760\n",
            "Epoch 35/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5757 - acc: 0.6915 - val_loss: 0.5855 - val_acc: 0.6870\n",
            "Epoch 36/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5794 - acc: 0.6910 - val_loss: 0.6041 - val_acc: 0.6750\n",
            "Epoch 37/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5738 - acc: 0.6955 - val_loss: 0.5889 - val_acc: 0.6850\n",
            "Epoch 38/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5737 - acc: 0.7045 - val_loss: 0.6156 - val_acc: 0.6630\n",
            "Epoch 39/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5799 - acc: 0.6995 - val_loss: 0.5813 - val_acc: 0.6940\n",
            "Epoch 40/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5786 - acc: 0.7035 - val_loss: 0.5850 - val_acc: 0.6840\n",
            "Epoch 41/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5635 - acc: 0.7030 - val_loss: 0.6398 - val_acc: 0.6210\n",
            "Epoch 42/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5759 - acc: 0.6960 - val_loss: 0.5800 - val_acc: 0.6970\n",
            "Epoch 43/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5740 - acc: 0.6975 - val_loss: 0.5826 - val_acc: 0.6870\n",
            "Epoch 44/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5764 - acc: 0.6960 - val_loss: 0.5827 - val_acc: 0.6920\n",
            "Epoch 45/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5730 - acc: 0.7085 - val_loss: 0.5879 - val_acc: 0.6860\n",
            "Epoch 46/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5614 - acc: 0.7055 - val_loss: 0.5841 - val_acc: 0.6870\n",
            "Epoch 47/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5620 - acc: 0.7080 - val_loss: 0.5821 - val_acc: 0.6880\n",
            "Epoch 48/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5666 - acc: 0.6995 - val_loss: 0.5778 - val_acc: 0.6970\n",
            "Epoch 49/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5683 - acc: 0.6955 - val_loss: 0.6136 - val_acc: 0.6480\n",
            "Epoch 50/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5652 - acc: 0.7035 - val_loss: 0.5789 - val_acc: 0.7000\n",
            "Epoch 51/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5568 - acc: 0.7105 - val_loss: 0.5751 - val_acc: 0.7030\n",
            "Epoch 52/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5558 - acc: 0.7095 - val_loss: 0.5877 - val_acc: 0.6830\n",
            "Epoch 53/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5628 - acc: 0.7050 - val_loss: 0.5855 - val_acc: 0.6820\n",
            "Epoch 54/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5600 - acc: 0.7155 - val_loss: 0.5792 - val_acc: 0.6960\n",
            "Epoch 55/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5509 - acc: 0.7160 - val_loss: 0.5737 - val_acc: 0.7010\n",
            "Epoch 56/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5594 - acc: 0.6935 - val_loss: 0.5731 - val_acc: 0.7030\n",
            "Epoch 57/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5528 - acc: 0.7150 - val_loss: 0.5750 - val_acc: 0.7010\n",
            "Epoch 58/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5494 - acc: 0.7130 - val_loss: 0.5804 - val_acc: 0.6900\n",
            "Epoch 59/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5534 - acc: 0.7155 - val_loss: 0.5896 - val_acc: 0.6810\n",
            "Epoch 60/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5448 - acc: 0.7190 - val_loss: 0.5771 - val_acc: 0.7030\n",
            "Epoch 61/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5454 - acc: 0.7240 - val_loss: 0.5957 - val_acc: 0.6680\n",
            "Epoch 62/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5484 - acc: 0.7145 - val_loss: 0.5744 - val_acc: 0.7010\n",
            "Epoch 63/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5470 - acc: 0.7100 - val_loss: 0.6011 - val_acc: 0.6570\n",
            "Epoch 64/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5480 - acc: 0.7145 - val_loss: 0.5783 - val_acc: 0.7020\n",
            "Epoch 65/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5442 - acc: 0.7220 - val_loss: 0.5711 - val_acc: 0.7040\n",
            "Epoch 66/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5442 - acc: 0.7255 - val_loss: 0.5717 - val_acc: 0.7130\n",
            "Epoch 67/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5489 - acc: 0.7220 - val_loss: 0.5783 - val_acc: 0.6890\n",
            "Epoch 68/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5421 - acc: 0.7225 - val_loss: 0.5740 - val_acc: 0.6980\n",
            "Epoch 69/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5409 - acc: 0.7120 - val_loss: 0.5749 - val_acc: 0.6940\n",
            "Epoch 70/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5377 - acc: 0.7315 - val_loss: 0.5743 - val_acc: 0.6940\n",
            "Epoch 71/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5388 - acc: 0.7225 - val_loss: 0.5688 - val_acc: 0.7020\n",
            "Epoch 72/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5399 - acc: 0.7245 - val_loss: 0.6033 - val_acc: 0.6550\n",
            "Epoch 73/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5356 - acc: 0.7260 - val_loss: 0.5750 - val_acc: 0.7030\n",
            "Epoch 74/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5403 - acc: 0.7205 - val_loss: 0.5685 - val_acc: 0.7110\n",
            "Epoch 75/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5294 - acc: 0.7280 - val_loss: 0.6263 - val_acc: 0.6540\n",
            "Epoch 76/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5335 - acc: 0.7215 - val_loss: 0.5728 - val_acc: 0.6980\n",
            "Epoch 77/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5289 - acc: 0.7370 - val_loss: 0.5785 - val_acc: 0.6940\n",
            "Epoch 78/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5283 - acc: 0.7325 - val_loss: 0.5903 - val_acc: 0.6830\n",
            "Epoch 79/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5287 - acc: 0.7335 - val_loss: 0.5683 - val_acc: 0.7000\n",
            "Epoch 80/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5342 - acc: 0.7245 - val_loss: 0.5767 - val_acc: 0.6920\n",
            "Epoch 81/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5320 - acc: 0.7325 - val_loss: 0.5733 - val_acc: 0.7030\n",
            "Epoch 82/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5240 - acc: 0.7315 - val_loss: 0.5660 - val_acc: 0.7020\n",
            "Epoch 83/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5279 - acc: 0.7340 - val_loss: 0.5693 - val_acc: 0.6980\n",
            "Epoch 84/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5197 - acc: 0.7340 - val_loss: 0.5757 - val_acc: 0.6960\n",
            "Epoch 85/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5276 - acc: 0.7415 - val_loss: 0.5755 - val_acc: 0.7000\n",
            "Epoch 86/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5251 - acc: 0.7355 - val_loss: 0.5667 - val_acc: 0.7190\n",
            "Epoch 87/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5291 - acc: 0.7380 - val_loss: 0.6124 - val_acc: 0.6620\n",
            "Epoch 88/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5231 - acc: 0.7265 - val_loss: 0.5669 - val_acc: 0.7170\n",
            "Epoch 89/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5204 - acc: 0.7430 - val_loss: 0.5833 - val_acc: 0.6850\n",
            "Epoch 90/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5229 - acc: 0.7265 - val_loss: 0.5961 - val_acc: 0.6790\n",
            "Epoch 91/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5142 - acc: 0.7445 - val_loss: 0.5667 - val_acc: 0.7100\n",
            "Epoch 92/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5195 - acc: 0.7320 - val_loss: 0.5694 - val_acc: 0.7120\n",
            "Epoch 93/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5092 - acc: 0.7430 - val_loss: 0.6105 - val_acc: 0.6620\n",
            "Epoch 94/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5153 - acc: 0.7425 - val_loss: 0.5968 - val_acc: 0.6780\n",
            "Epoch 95/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5161 - acc: 0.7340 - val_loss: 0.7256 - val_acc: 0.5940\n",
            "Epoch 96/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5196 - acc: 0.7420 - val_loss: 0.5696 - val_acc: 0.6970\n",
            "Epoch 97/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5142 - acc: 0.7455 - val_loss: 0.5663 - val_acc: 0.7080\n",
            "Epoch 98/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5126 - acc: 0.7425 - val_loss: 0.5711 - val_acc: 0.7080\n",
            "Epoch 99/100\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 0.5160 - acc: 0.7385 - val_loss: 0.5647 - val_acc: 0.7090\n",
            "Epoch 100/100\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.5054 - acc: 0.7440 - val_loss: 0.5666 - val_acc: 0.7100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qlpBgacRW75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScLnxwBrRW6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=range(1, len(acc)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjQYG4EERW32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "2e75b6bb-fdb7-4820-db21-c9b7f0c89d6c"
      },
      "source": [
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQkVfURQliVDRVxRFSSJU9BVFUZKI/we1M4GKLwhhjwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}